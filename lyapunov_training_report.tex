
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{datetime}
\pagestyle{fancy}
\fancyhf{}
\rhead{Lyapunov Training Report}
\lhead{}
\rfoot{Page \thepage}

\title{Lyapunov Function Training Report}
\author{}
\date{\today\ at \currenttime}

\begin{document}
\maketitle
\thispagestyle{fancy}

\section*{1. Tracking Error History}
Tracking error ($e$) is the difference between the reference ($r$) and the actual value ($x$):
\begin{equation}
e = r - x.
\end{equation}

\indent The subsequent plot illustrates the historical tracking error data, which serves as input for the neural network.

\begin{center}
\includegraphics[width=0.85\textwidth]{tracking_error_history.pdf}
\end{center}

\section*{2. Training Summary}
Lyapunov candidate training completed.
\begin{itemize}
  \item  Loss is decreasing.
  \item  Final loss below threshold.
\end{itemize}

\begin{center}
\includegraphics[width=0.85\textwidth]{loss_history.pdf}
\end{center}

\section*{3. Final Lyapunov Form}
The Lyapunov function ($V$) is synthesized based on the Cholesky factorization:

\begin{equation}
V = 
\begin{bmatrix}
e & \dot{e}
\end{bmatrix}
A
\begin{bmatrix}
e \\
\dot{e}
\end{bmatrix},
\end{equation}

\begin{equation}
A = L L^\top,
\end{equation}
where $L$ is the Cholesky factor.

The final learned matrices:
\begin{verbatim}
L = 
    [2.08  0.00]
    [-0.09  0.78]

A = 
    [4.32  -0.19]
    [-0.19  0.62]

A = L @ L.T
\end{verbatim}

\section*{4. Lyapunov Surface}
\includegraphics[width=0.85\textwidth]{lyapunov_surface.png}

\section*{5. Final Constraint Inequality}
\begin{verbatim}
dV + lambda * V <= epsilon
lambda = 0.1, epsilon = 3.0762\end{verbatim}

\section*{6. Constraint Curve}
\includegraphics[width=0.85\textwidth]{training_constraint_curve.png}

\end{document}