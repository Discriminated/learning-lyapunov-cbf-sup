
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{datetime}
\pagestyle{fancy}
\fancyhf{}
\rhead{Lyapunov Training Report}
\lhead{}
\rfoot{Page \thepage}

\title{Lyapunov Function Training Report}
\author{}
\date{\today\ at \currenttime}

\begin{document}
\maketitle
\thispagestyle{fancy}

\section*{1. Tracking Error History}
Tracking error ($e$) is the difference between the reference ($r$) and the actual value ($x$):
\begin{equation}
e = r - x.
\end{equation}

\indent The subsequent plot illustrates the historical tracking error data, which serves as input for the neural network.

\begin{center}
\includegraphics[width=0.85\textwidth]{tracking_error_history.pdf}
\end{center}

\section*{2. Training Summary}
Lyapunov candidate training completed.
\begin{itemize}
  \item  Loss is decreasing.
  \item  Final loss below threshold.
\end{itemize}

\begin{center}
\includegraphics[width=0.85\textwidth]{loss_history.pdf}
\end{center}

\section*{3. Final Lyapunov Form}
The Lyapunov function ($V$) is synthesized based on the Cholesky factorization:

\begin{equation}
V = 
\begin{bmatrix}
e & \dot{e}
\end{bmatrix}
A
\begin{bmatrix}
e \\
\dot{e}
\end{bmatrix},
\end{equation}

\begin{equation}
A = L L^\top,
\end{equation}
where $L$ is the Cholesky factor.

The final learned matrices:
\begin{align}
L &= \begin{bmatrix}
1.09 & 0.00 \\
-0.08 & 0.58 \\
\end{bmatrix}, \\
A &= \begin{bmatrix}
1.20 & -0.08 \\
-0.08 & 0.34 \\
\end{bmatrix}.
\end{align}

\section*{4. Lyapunov Surface}
\includegraphics[width=0.85\textwidth]{lyapunov_surface.png}

\section*{5. Final Constraint Inequality}
The final constraint inequality is given by:
\begin{equation}
\dot{V} + \lambda V \leq \epsilon,
\end{equation}
where $\lambda = 0.1$, $\epsilon = 0.1222$.

\section*{6. Constraint Curve}
\includegraphics[width=0.85\textwidth]{training_constraint_curve.png}

\end{document}